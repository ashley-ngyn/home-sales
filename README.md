# home sales #
* sparksql
* spark
    * temporary views
    * parition data (parquet)
    * cache/uncache temporary table

## Instructions ##
1. Create temporary table called home_sales
2. Answer questions using SparkSQL
3. Cache temporary table home_sales
    * check if table is cached
4. Partition by "date_built" field on formatted parquet home sales data
5. Create temporary table for parquet data
6. Uncache home_sales temporary table
    * verify if uncached using PySpark

## Results ##
<img width="884" alt="1" src="https://github.com/ashley-ngyn/home-sales/assets/150317761/c419f0fb-ff8c-40e9-9416-68cd1e64bc05"> <br/><br/>
<img width="632" alt="2" src="https://github.com/ashley-ngyn/home-sales/assets/150317761/764ca511-557f-4121-8b07-41553555a27a"> <br/><br/>
<img width="728" alt="3" src="https://github.com/ashley-ngyn/home-sales/assets/150317761/a883e823-df25-4ba4-8f51-eae17e1d150a"> <br/><br/>
<img width="834" alt="4" src="https://github.com/ashley-ngyn/home-sales/assets/150317761/fa53bf7a-f235-454c-8d4b-4a979515507d"> <br/><br/>
